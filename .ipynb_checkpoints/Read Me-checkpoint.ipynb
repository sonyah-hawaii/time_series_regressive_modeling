{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ ME\n",
    "## Data Sources:\n",
    "- [EnerData Global Statistical Yearbook](https://yearbook.enerdata.net/)\n",
    "- [World Bank (CO2 Emissions)](https://data.worldbank.org/indicator/EN.CO2.ETOT.ZS)\n",
    "- [World Bank (GDP Per Capita](https://data.worldbank.org/indicator/NY.GDP.PCAP.CD)\n",
    "- [World Intellectual Property Organization](http://www.wipo.int/econ_stat/en/economics/research/)\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data cleaning & target development](https://github.com/sonyah-hawaii/time_series_regressive_modeling/blob/master/Cleaning%20%26%20Abatement%20Calculations.ipynb)       \n",
    "_This notebook details the steps to calculate units of CO2 Abated annually. A full list of countries included in the dataset can be found here_\n",
    "- [Developing profiles with K-Means clustering](https://github.com/sonyah-hawaii/time_series_regressive_modeling/blob/master/clustering.ipynb)  \n",
    "_This notebook generates yoy change using `.diff` and passes that information through K-Means, using the resulting labels to develop cohorts for modeling._\n",
    "- [Variance Analysis of Clusters/Cohorts](https://github.com/sonyah-hawaii/time_series_regressive_modeling/blob/master/Variance%20Analysis.ipynb)  \n",
    "_This notebook takes in results of K-Means to develop tables that summarize variance, and distinguishes differences in patterns between cohorts._\n",
    "- [Regression Models](https://github.com/sonyah-hawaii/time_series_regressive_modeling/blob/master/time_series.ipynb)\n",
    "\n",
    "These notebooks includes the following packages and languages:\n",
    "- `Numpy` and `Pandas`\n",
    "- `Scikitlearn`\n",
    "- `pymc3`\n",
    "- `Seaborn` and `Matplotlib`  \n",
    "- Python, LaTex, and Markdown\n",
    "\n",
    "## Executive Summary:  \n",
    "\n",
    "This project aims to gain understanding of working with a small dataset with high variance. Utilizing metrics of production and emissions trends, the target (abatement in metric tons of CO2) was developed and passed through 3 regressive models to test different approaches to incorporate variance into the modeling process. The dataset is comprised of:\n",
    "\n",
    "The data spanned 27 countries over 25 years, and each model trained and tested on historical data with 15 lags. The training model aimed to predict abatement from 2005-2013, and the test model predicted 2014. Models tested were traditional autoregressive model, Random Forest Regressor from `scikitlearn` and Bayesian autoregression with `pymc3`. Before the modeling process the data was passed through K-Means to develop cohorts for modeling.   \n",
    "A primary focus of this is to assess what Bayesian regression can offer us in terms of incorporating distributions into future predictions. Overall, the model performed better than traditional Autoregressive models, but in some cases not as well as Random Forest Regressor. The traditional autoregressive model acted as a baseline, while Random Forest Regressor was included to test the efficacy of an ensemble method on making difficult predictions. The Bayesian model is distinguished from the other regressions by incorporating variance ($\\epsilon_i$) through informed distributions.\n",
    "\n",
    "$$y_{t} = \\beta_0 + \\sum_{i=1}^{t}\\beta_i y_{t-i} +  \\sum_{i=1}^{N}\\beta_j x_{ji} + \\epsilon_i$$ \n",
    "\n",
    "$$\\beta_0 \\sim Skew Normal(1.75, 1)$$\n",
    "\n",
    "$$\\beta_1 \\sim Skew Normal(1.75, 1)$$\n",
    "\n",
    "$$\\epsilon \\sim Half Normal(1, 0)$$  \n",
    "\n",
    "                             The best model utilized these distributions, taking in parameters for Standard Deviation and Skewness\n",
    "                           \n",
    "                           \n",
    "With the traditional autoregressive model, it often was able to predict increases in abatement, or capture the peaks in trends, but often lost integrity when predicting troughs. The best Bayesian model was built for Cohort 1, which included the largest group of countries (topping off at 25 of the 35 countries). It scored with a 0.8 for train and 0.64 for test (R2), a marked improvement from the traditional regression's score of 1 on train and -1.18 on test. Across all cohorts, Random Forest Regressor and traditional autoregressive model performed the best; however, the two cohorts modeled using Bayesian autoregression had divergent results, proving they are both excellent subsets to explore how Bayes can improve upon traditional regression, as well as how it can be fine-tuned. \n",
    "\n",
    "This project entailed building a series of loops that developed lagged train and test dataset, passed cohorts through the modeling process, and output useable markdown tables. For the Bayesian autoregression, this entailed developing informed priors by passing individual countries through MCMC, and ensembling the resulting predictions for individual countries to determine R2. Additionally, it demanded meticulous organization and information tracking within codes. Each notebook stands and runs through independently.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make read me a blog post and link it to github (leave the readme in github folder, too)\n",
    "\n",
    "- read me has links to the specific section referred to, notebook has a link back to the readme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within notebooks:\n",
    "- include another table of contents\n",
    "- every section should have a brief description with goals\n",
    "- the end of every section should have a summary looking at what goals were accomplished, what expetations were/were not met, how analysis would continue given time\n",
    "- showcasing ideas as well as the work\n",
    "- each notebook should end with a link to the next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Initial visualization of global trends_\n",
    "\n",
    "<a id='visualization'></a>\n",
    "\n",
    "\n",
    "- generate a for loop to create a distribution per year of my given metric\n",
    "- plt.save_fig or something like that, png files\n",
    "- imagemagick (command line tool)  \n",
    "\n",
    "- the ratio of renewable energy production to conventional energy production\n",
    "- andrews curves\n",
    "\n",
    "\n",
    "- possibly that the demand for electriity increased while renewable energy stayed level\n",
    "- could be related to oil price around dot com era, maybe these institutions are contributing to electricity consumption\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
